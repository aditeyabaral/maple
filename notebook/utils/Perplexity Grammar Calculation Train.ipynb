{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ALqQaEKgXeYr"
   },
   "source": [
    "https://www.scribendi.ai/comparing-bert-and-gpt-2-as-language-models-to-score-the-grammatical-correctness-of-a-sentence/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JaGODSpcnTzB"
   },
   "source": [
    "# Installing Java-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "3N2ILHKbprar"
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tfsblkFQk88J",
    "outputId": "09f385ef-69d2-4a16-ce50-c63151c524ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "Note, selecting 'openjdk-9-jre-headless' for glob 'openjdk-*'\n",
      "Note, selecting 'openjdk-8-jdk' for glob 'openjdk-*'\n",
      "Note, selecting 'openjdk-8-jre' for glob 'openjdk-*'\n",
      "Note, selecting 'openjdk-6-jre' for glob 'openjdk-*'\n",
      "Note, selecting 'openjdk-6-jre-headless' for glob 'openjdk-*'\n",
      "Note, selecting 'openjdk-11-demo' for glob 'openjdk-*'\n",
      "Note, selecting 'openjdk-8-demo' for glob 'openjdk-*'\n",
      "Note, selecting 'openjdk-11-source' for glob 'openjdk-*'\n",
      "Note, selecting 'openjdk-8-jre-dcevm' for glob 'openjdk-*'\n",
      "Note, selecting 'openjdk-11-jre-headless' for glob 'openjdk-*'\n",
      "Note, selecting 'openjdk-11-dbg' for glob 'openjdk-*'\n",
      "Note, selecting 'openjdk-11-doc' for glob 'openjdk-*'\n",
      "Note, selecting 'openjdk-8-jdk-headless' for glob 'openjdk-*'\n",
      "Note, selecting 'openjdk-7-jre-headless' for glob 'openjdk-*'\n",
      "Note, selecting 'openjdk-8-jre-zero' for glob 'openjdk-*'\n",
      "Note, selecting 'openjdk-8-source' for glob 'openjdk-*'\n",
      "Note, selecting 'openjdk-jre' for glob 'openjdk-*'\n",
      "Note, selecting 'openjdk-11-jdk' for glob 'openjdk-*'\n",
      "Note, selecting 'openjdk-11-jre' for glob 'openjdk-*'\n",
      "Note, selecting 'openjdk-11-jre-zero' for glob 'openjdk-*'\n",
      "Note, selecting 'openjdk-7-jdk' for glob 'openjdk-*'\n",
      "Note, selecting 'openjdk-10-jdk-headless' for glob 'openjdk-*'\n",
      "Note, selecting 'openjdk-7-jre' for glob 'openjdk-*'\n",
      "Note, selecting 'openjdk-9-jdk-headless' for glob 'openjdk-*'\n",
      "Note, selecting 'openjdk-8-jre-headless' for glob 'openjdk-*'\n",
      "Note, selecting 'openjdk-11-jre-dcevm' for glob 'openjdk-*'\n",
      "Note, selecting 'openjdk-11-jdk-headless' for glob 'openjdk-*'\n",
      "Note, selecting 'openjdk-8-dbg' for glob 'openjdk-*'\n",
      "Note, selecting 'openjdk-8-doc' for glob 'openjdk-*'\n",
      "Package 'openjdk-6-jre-headless' is not installed, so not removed\n",
      "Package 'openjdk-7-jdk' is not installed, so not removed\n",
      "Package 'openjdk-6-jre' is not installed, so not removed\n",
      "Package 'openjdk-7-jre' is not installed, so not removed\n",
      "Package 'openjdk-7-jre-headless' is not installed, so not removed\n",
      "Package 'openjdk-9-jre-headless' is not installed, so not removed\n",
      "Package 'openjdk-jre' is not installed, so not removed\n",
      "Package 'openjdk-9-jdk-headless' is not installed, so not removed\n",
      "Package 'openjdk-10-jdk-headless' is not installed, so not removed\n",
      "Note, selecting 'icedtea-gcjwebplugin' for glob 'icedtea-*'\n",
      "Note, selecting 'icedtea-netx-common' for glob 'icedtea-*'\n",
      "Note, selecting 'icedtea-8-plugin' for glob 'icedtea-*'\n",
      "Note, selecting 'icedtea-netx' for glob 'icedtea-*'\n",
      "Note, selecting 'icedtea-plugin' for glob 'icedtea-*'\n",
      "Package 'icedtea-gcjwebplugin' is not installed, so not removed\n",
      "Note, selecting 'icedtea6-plugin' for glob 'icedtea6-*'\n",
      "Package 'icedtea6-plugin' is not installed, so not removed\n",
      "Package 'openjdk-8-jre-dcevm' is not installed, so not removed\n",
      "Package 'openjdk-11-dbg' is not installed, so not removed\n",
      "Package 'openjdk-11-doc' is not installed, so not removed\n",
      "Package 'openjdk-11-jdk' is not installed, so not removed\n",
      "Package 'openjdk-11-jdk-headless' is not installed, so not removed\n",
      "Package 'openjdk-11-jre' is not installed, so not removed\n",
      "Package 'openjdk-11-jre-headless' is not installed, so not removed\n",
      "Package 'openjdk-11-source' is not installed, so not removed\n",
      "Package 'icedtea-8-plugin' is not installed, so not removed\n",
      "Package 'icedtea-netx' is not installed, so not removed\n",
      "Package 'icedtea-netx-common' is not installed, so not removed\n",
      "Package 'icedtea-plugin' is not installed, so not removed\n",
      "Package 'openjdk-11-demo' is not installed, so not removed\n",
      "Package 'openjdk-11-jre-dcevm' is not installed, so not removed\n",
      "Package 'openjdk-11-jre-zero' is not installed, so not removed\n",
      "Package 'openjdk-8-dbg' is not installed, so not removed\n",
      "Package 'openjdk-8-demo' is not installed, so not removed\n",
      "Package 'openjdk-8-doc' is not installed, so not removed\n",
      "Package 'openjdk-8-jdk' is not installed, so not removed\n",
      "Package 'openjdk-8-jre' is not installed, so not removed\n",
      "Package 'openjdk-8-jre-zero' is not installed, so not removed\n",
      "Package 'openjdk-8-source' is not installed, so not removed\n",
      "The following packages were automatically installed and are no longer required:\n",
      "  cuda-command-line-tools-10-0 cuda-command-line-tools-10-1 cuda-compiler-10-0\n",
      "  cuda-compiler-10-1 cuda-cuobjdump-10-0 cuda-cuobjdump-10-1 cuda-cupti-10-0\n",
      "  cuda-cupti-10-1 cuda-demo-suite-10-0 cuda-demo-suite-10-1\n",
      "  cuda-demo-suite-11-0 cuda-documentation-10-0 cuda-documentation-10-1\n",
      "  cuda-documentation-11-0 cuda-drivers cuda-drivers-465 cuda-gdb-10-0\n",
      "  cuda-gdb-10-1 cuda-gpu-library-advisor-10-0 cuda-gpu-library-advisor-10-1\n",
      "  cuda-libraries-10-0 cuda-libraries-10-1 cuda-memcheck-10-0\n",
      "  cuda-memcheck-10-1 cuda-nsight-compute-10-0 cuda-nsight-compute-10-1\n",
      "  cuda-nsight-compute-11-0 cuda-nsight-systems-10-1 cuda-nsight-systems-11-0\n",
      "  cuda-nvcc-10-0 cuda-nvcc-10-1 cuda-nvdisasm-10-0 cuda-nvdisasm-10-1\n",
      "  cuda-nvml-dev-10-0 cuda-nvml-dev-10-1 cuda-nvprof-10-0 cuda-nvprof-10-1\n",
      "  cuda-nvprune-10-0 cuda-nvprune-10-1 cuda-nvtx-10-0 cuda-nvtx-10-1\n",
      "  cuda-runtime-10-0 cuda-runtime-10-1 cuda-runtime-11-0 cuda-samples-10-0\n",
      "  cuda-samples-10-1 cuda-samples-11-0 cuda-sanitizer-api-10-1 dkms freeglut3\n",
      "  freeglut3-dev java-common keyboard-configuration libargon2-0 libcap2\n",
      "  libcryptsetup12 libdevmapper1.02.1 libfontenc1 libidn11 libip4tc0\n",
      "  libjansson4 libnvidia-cfg1-465 libnvidia-common-460 libnvidia-common-465\n",
      "  libnvidia-decode-465 libnvidia-encode-465 libnvidia-extra-465\n",
      "  libnvidia-fbc1-465 libnvidia-gl-465 libnvidia-ifr1-465 libpam-systemd\n",
      "  libpcsclite1 libpolkit-agent-1-0 libpolkit-backend-1-0 libpolkit-gobject-1-0\n",
      "  libxfont2 libxi-dev libxkbfile1 libxmu-dev libxmu-headers libxnvctrl0\n",
      "  libxtst6 nsight-compute-2021.1.0 nsight-systems-2020.3.2\n",
      "  nsight-systems-2021.1.3 nvidia-compute-utils-465 nvidia-dkms-465\n",
      "  nvidia-driver-465 nvidia-kernel-common-465 nvidia-kernel-source-465\n",
      "  nvidia-modprobe nvidia-settings nvidia-utils-465 policykit-1\n",
      "  policykit-1-gnome python3-xkit screen-resolution-extra systemd systemd-sysv\n",
      "  udev x11-xkb-utils xserver-common xserver-xorg-core-hwe-18.04\n",
      "  xserver-xorg-video-nvidia-465\n",
      "Use 'apt autoremove' to remove them.\n",
      "The following packages will be REMOVED:\n",
      "  ca-certificates-java* openjdk-8-jdk-headless* openjdk-8-jre-headless*\n",
      "0 upgraded, 0 newly installed, 3 to remove and 34 not upgraded.\n",
      "After this operation, 143 MB disk space will be freed.\n",
      "(Reading database ... 153596 files and directories currently installed.)\n",
      "Removing openjdk-8-jdk-headless:amd64 (8u282-b08-0ubuntu1~18.04) ...\n",
      "Removing ca-certificates-java (20180516ubuntu1~18.04.1) ...\n",
      "Removing openjdk-8-jre-headless:amd64 (8u282-b08-0ubuntu1~18.04) ...\n",
      "Processing triggers for ca-certificates (20210119~18.04.1) ...\n",
      "Updating certificates in /etc/ssl/certs...\n",
      "0 added, 0 removed; done.\n",
      "Running hooks in /etc/ca-certificates/update.d...\n",
      "\n",
      "updates of cacerts keystore disabled.\n",
      "done.\n",
      "(Reading database ... 153265 files and directories currently installed.)\n",
      "Purging configuration files for ca-certificates-java (20180516ubuntu1~18.04.1) ...\n",
      "Purging configuration files for openjdk-8-jre-headless:amd64 (8u282-b08-0ubuntu1~18.04) ...\n",
      "openjdk version \"1.8.0_282\"\n",
      "OpenJDK Runtime Environment (build 1.8.0_282-8u282-b08-0ubuntu1~18.04-b08)\n",
      "OpenJDK 64-Bit Server VM (build 25.282-b08, mixed mode)\n"
     ]
    }
   ],
   "source": [
    "!apt-get purge openjdk-\\* icedtea-\\* icedtea6-\\*\n",
    "!apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "!java -version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9zII8VL8t27G"
   },
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3Wp8rJB_DN6B",
    "outputId": "bb1f6026-a8b2-4c0e-deea-4c146c7c917e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/b2/57495b5309f09fa501866e225c84532d1fd89536ea62406b2181933fb418/transformers-4.5.1-py3-none-any.whl (2.1MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1MB 4.8MB/s \n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
      "Collecting tokenizers<0.11,>=0.10.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n",
      "\u001b[K     |████████████████████████████████| 3.3MB 37.2MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
      "Collecting sacremoses\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
      "\u001b[K     |████████████████████████████████| 901kB 48.2MB/s \n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.10.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
      "Installing collected packages: tokenizers, sacremoses, transformers\n",
      "Successfully installed sacremoses-0.0.45 tokenizers-0.10.2 transformers-4.5.1\n",
      "Collecting language_check\n",
      "  Downloading https://files.pythonhosted.org/packages/97/45/0fd1d3683d6129f30fa09143fa383cdf6dff8bc0d1648f2cf156109cb772/language-check-1.1.tar.gz\n",
      "Building wheels for collected packages: language-check\n",
      "  Building wheel for language-check (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for language-check: filename=language_check-1.1-cp37-none-any.whl size=90190897 sha256=45471e3bf95f9f4485621345f1fb9347c05a59a9f239e38a6546a33375a7e978\n",
      "  Stored in directory: /root/.cache/pip/wheels/d5/46/82/90a89c23eac1837364ed7217a9eed71bc9e6ad4825be93968e\n",
      "Successfully built language-check\n",
      "Installing collected packages: language-check\n",
      "Successfully installed language-check-1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install language_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "t3px79vcDWe1"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import language_check\n",
    "import matplotlib.pyplot as plt\n",
    "from google.colab import files\n",
    "from transformers import GPT2LMHeadModel, GPT2TokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "YT49k5Z0mmEV"
   },
   "outputs": [],
   "source": [
    "tool_us = language_check.LanguageTool('en-US')\n",
    "tool_uk = language_check.LanguageTool('en-GB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ylAiZOjet6B7"
   },
   "source": [
    "# Reading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ax16JtDvrQ21"
   },
   "outputs": [],
   "source": [
    "with open (\"/content/drive/MyDrive/Colab Notebooks/dataset.json\") as d:\n",
    "  dfd_json = json.load(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "NuviNeMRof6L"
   },
   "outputs": [],
   "source": [
    "poems = list()\n",
    "haikus = list()\n",
    "indices = list()\n",
    "\n",
    "MIN_THRESHOLD_HAIKU = 5\n",
    "MAX_THRESHOLD_POEM = 120\n",
    "\n",
    "for dataset in dfd_json:\n",
    "  for poem in dataset:\n",
    "    for grammar_index in poem:\n",
    "      if grammar_index == \"poem\":\n",
    "        continue\n",
    "      else:\n",
    "        haiku_data = poem[grammar_index]\n",
    "        for haiku, index in list(haiku_data.items()):\n",
    "          if len(index) >= MIN_THRESHOLD_HAIKU and len(poem[\"poem\"].split()) <= MAX_THRESHOLD_POEM:\n",
    "            poems.append(poem[\"poem\"])\n",
    "            haikus.append(haiku)\n",
    "            indices.append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D9KJqsRsu9zk",
    "outputId": "a89bb43d-8a57-4853-c940-706ff50f402d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54629, 54629, 54629)"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(poems), len(haikus), len(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "d7CtJCzCu92G"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df[\"poem\"] = poems\n",
    "df[\"haiku\"] = haikus\n",
    "df[\"indices\"] = indices\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 212
    },
    "id": "95xjsG-du948",
    "outputId": "c6a2d239-0c7c-4732-8538-06ee01604ec2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54629, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>poem</th>\n",
       "      <th>haiku</th>\n",
       "      <th>indices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Did the CIA tell the FBI that it knows the wor...</td>\n",
       "      <td>cia fbi the biggest weapon</td>\n",
       "      <td>[2, 5, 9, 24, 25]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Did the CIA tell the FBI that it knows the wor...</td>\n",
       "      <td>cia fbi the biggest weapon</td>\n",
       "      <td>[2, 5, 9, 24, 25]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dark clouds gathered overhead,\\nExpelling bull...</td>\n",
       "      <td>clouds overhead bullets of the valley</td>\n",
       "      <td>[1, 3, 5, 6, 10, 11]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A vigilante lacking of heroic qualities that\\n...</td>\n",
       "      <td>lacking qualities that damn criminals</td>\n",
       "      <td>[2, 5, 6, 11, 12]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(A Diamante Poem)\\nBrain\\nHeavenly, hellish\\nF...</td>\n",
       "      <td>diamante poem the sybaritic pathetic</td>\n",
       "      <td>[1, 2, 10, 18, 19]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                poem  ...               indices\n",
       "0  Did the CIA tell the FBI that it knows the wor...  ...     [2, 5, 9, 24, 25]\n",
       "1  Did the CIA tell the FBI that it knows the wor...  ...     [2, 5, 9, 24, 25]\n",
       "2  Dark clouds gathered overhead,\\nExpelling bull...  ...  [1, 3, 5, 6, 10, 11]\n",
       "3  A vigilante lacking of heroic qualities that\\n...  ...     [2, 5, 6, 11, 12]\n",
       "4  (A Diamante Poem)\\nBrain\\nHeavenly, hellish\\nF...  ...    [1, 2, 10, 18, 19]\n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eFphLqB_D91W"
   },
   "source": [
    "# Defining Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "yH_N9nvwDdXa"
   },
   "outputs": [],
   "source": [
    "def perplexityGPT2(sentences):\n",
    "  model_id = 'gpt2'\n",
    "  model = GPT2LMHeadModel.from_pretrained(model_id)\n",
    "  tokenizer = GPT2TokenizerFast.from_pretrained(model_id)\n",
    "\n",
    "  ppl = list()\n",
    "  total_length = len(sentences)\n",
    "  for index, sent in enumerate(sentences):\n",
    "    if not (index+1)%1000:\n",
    "      print(f\"{index+1}/{total_length}\")\n",
    "    tokenize_input = tokenizer.encode(sent)\n",
    "    tensor_input = torch.tensor([tokenize_input])\n",
    "    loss = model(tensor_input, labels=tensor_input)[0]\n",
    "    ppl.append(math.exp(loss))\n",
    "\n",
    "  return ppl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "Uz0Tn87tmxhk"
   },
   "outputs": [],
   "source": [
    "def checkGrammar(sentences):\n",
    "  result = list()\n",
    "  total_length = len(sentences)\n",
    "  for index, sent in enumerate(sentences):\n",
    "    if not (index+1)%1000:\n",
    "      print(f\"{index+1}/{total_length}\")\n",
    "    flag_us = not bool(tool_us.check(sent))\n",
    "    flag_uk = not bool(tool_uk.check(sent))\n",
    "    result.append(flag_us or flag_uk)\n",
    "  return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-1mz4I-hpS5E"
   },
   "source": [
    "# Calculating Perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qVGBu7jcNxHy"
   },
   "outputs": [],
   "source": [
    "ppl_scores_gpt2 = perplexityGPT2(list(df[\"haiku\"].values))\n",
    "df[\"ppl-gpt2\"] = ppl_scores_gpt2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aQ2cgAicpW8l"
   },
   "source": [
    "# Checking Grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ssJHs2uBm6cI",
    "outputId": "16b0c87f-b8af-49fa-8ab0-95cfa2a38107"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/54629\n"
     ]
    }
   ],
   "source": [
    "grammar_checks = checkGrammar(list(df[\"haiku\"].values))\n",
    "df[\"grammar-check\"] = grammar_checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9DMLVAYYpbOX"
   },
   "source": [
    "# Downloading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9WtrFQAGl6aw"
   },
   "outputs": [],
   "source": [
    "df.to_json(\"ppl-grammar-dataset.json\")\n",
    "files.download(\"ppl-grammar-dataset.json\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Perplexity_Grammar_Calculation_Train",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
